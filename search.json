[
  {
    "objectID": "presentation.html#introduce-the-topic-and-motivation",
    "href": "presentation.html#introduce-the-topic-and-motivation",
    "title": "Exonerations in the U.S.",
    "section": "Introduce the topic and motivation",
    "text": "Introduce the topic and motivation\n\n\n\n\n\n\n\nThe criminal justice system in the United States has been under scrutiny for its disproportionate impact on minority communities.\nWe want to investigate:\n\nhow race affects the severity of the sentences exonerees receive\nhow length of time between conviction and exoneration, severity of crime, and sentence are related\nhow false convictions are associated with harsher sentences and later found innocent"
  },
  {
    "objectID": "presentation.html#introduce-the-data",
    "href": "presentation.html#introduce-the-data",
    "title": "Exonerations in the U.S.",
    "section": "Introduce the data",
    "text": "Introduce the data\n\nObservations represent all known U.S. exonerees between 1989 and 2023.\nData was collected by The National Registry of Exonerations\nThe data fields consist of exoneree info such as name, race, and sex as well as information about their exoneration.\nData has several subpopulations"
  },
  {
    "objectID": "presentation.html#highlights-from-eda",
    "href": "presentation.html#highlights-from-eda",
    "title": "Exonerations in the U.S.",
    "section": "Highlights from EDA",
    "text": "Highlights from EDA\n\n\n\n\n\n\n\n  \n    \n    \n      race\n      num\n      prop\n    \n  \n  \n    Asian\n32\n0.0097442144\n    Black\n1724\n0.5249695493\n    Black;#White\n1\n0.0003045067\n    Don't Know\n7\n0.0021315469\n    Hispanic\n400\n0.1218026797\n    Native American\n22\n0.0066991474\n    Native American;#White\n1\n0.0003045067\n    Other\n19\n0.0057856273\n    White\n1078\n0.3282582217\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\nAsian, Black, White, Hispanic, and Native American exonerees appear the most in the data set\n\nNative American and Black exonerees often spend longer between conviction and exoneration than exonerees of other races."
  },
  {
    "objectID": "presentation.html#inferencemodelingother-analysis",
    "href": "presentation.html#inferencemodelingother-analysis",
    "title": "Exonerations in the U.S.",
    "section": "Inference/modeling/other analysis",
    "text": "Inference/modeling/other analysis\nYour results here"
  },
  {
    "objectID": "presentation.html#inferencemodelingother-analysis-1",
    "href": "presentation.html#inferencemodelingother-analysis-1",
    "title": "Exonerations in the U.S.",
    "section": "Inference/modeling/other analysis",
    "text": "Inference/modeling/other analysis\nYour results here"
  },
  {
    "objectID": "presentation.html#conclusions-future-work",
    "href": "presentation.html#conclusions-future-work",
    "title": "Exonerations in the U.S.",
    "section": "Conclusions + future work",
    "text": "Conclusions + future work\n\nHispanic exonerees have a stat. significant difference in predicted probabiliy of getting severe sentence than White exonerees\nHow about the rest of the exonerees?\n\n\n\nBlack exonerees have stat. significant difference compared to White exonerees in expected years between conviction and exoneration, holding sentence severity constant.\nWhat does this imply?\n\n\n\n\nKey Limitation: data only represents those who have already been found innocent, we cannot extrapolate to all falsely convicted people.\n\n\n\n\nFuture work:\n\nTransforming sentence into numeric field to examine how sentence length (in years) is associated with race and/or other factors"
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "Project title",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.0\n✔ tibble  3.2.1     ✔ dplyr   1.1.2\n✔ tidyr   1.2.1     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\n\nResearch question(s)\nWe aim to discover the relationship between certain characteristics of the exoneree and their case and the type of sentence that they received. More specifically, we want to know how race, age at time of the crime, sex, the time they spent before being exonerated, and the important details that led to their exoneration (perjury, inadequate legal defense, etc.) relate to the severity of their sentence.\nUsing this analysis, we hope to be able to use these variables to predict the severity of their sentence.\n\n\nData collection and cleaning\nHave an initial draft of your data cleaning appendix. Document every step that takes your raw data file(s) and turns it into the analysis-ready data set that you would submit with your final project. Include text narrative describing your data collection (downloading, scraping, surveys, etc) and any additional data curation/cleaning (merging data frames, filtering, transformations of variables, etc). Include code for data curation/cleaning, but not collection.\nFirst, we request and download the raw .csv file from the National Registry of Exonerations.\n\nhttps://www.law.umich.edu/special/exoneration/Pages/about.aspx\n\nNext, we load the csv file into a data frame. We name it us_exonerations.\n\nus_exonerations <- read_csv(\"data/us_exonerations.csv\")\n\nRows: 3284 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (20): Last Name, First Name, Race, Sex, State, County, Tags, Worst Crime...\ndbl  (3): Age, Convicted, Exonerated\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe dataset is already generally clean and tidy, with each row representing a exoneree and the various details of their case. However, there are some improvements to be made. First is the column names, which do not follow convention and include several strange characters in them. We use the janitor function clean_names to give the names a proper format.\nNext, we want to transform the tags column so we can use its contents for further analysis. Originally, these tags were contained in a “;#” separated string. To pull them out, we mutate our dataframe to include a new column that indicates whether or not the exoneree’s case included that tag.\nSeveral of the columns had values of NA or the name of the column itself to demonstrate a binary set of values. We convert these to simply 1 and 0 for ease of analysis.\nNext, we create a new column that represents the number of years between when an exoneree was convicted and when they were exonerated. This gives us an estimate of how long they spent in prison, on probation, or, more generally, faced the consequences of a crime they did not commit. We also add a column sentence_severity, which marks whether or not the exoneree was sentenced to a severe punishment (death, life in prison, or life without parole). These will aid us in our analysis later.\nFinally, we filter out the columns that we will not be using in our analysis or have already used in different forms (i.e. tags column).\n\nmost_severe <- c(\"Death\", \"Life without parole\", \"Life\")\n\n# turn tags into columns, mark 1 if tag present, 0 if not\nus_exonerations <- us_exonerations |>\n  clean_names() |>\n  rowwise() |>\n  mutate(\n    tags_vc = str_split(string = tags, pattern = \";#\"),\n    ars = if_else(\"A\" %in% tags_vc, 1, 0),\n    cdc = if_else(\"CDC\" %in% tags_vc, 1, 0),\n    ciu = if_else(\"CIU\" %in% tags_vc, 1, 0),\n    csh = if_else(\"CSH\" %in% tags_vc, 1, 0),\n    cv = if_else(\"CV\" %in% tags_vc, 1, 0),\n    fem = if_else(\"F\" %in% tags_vc, 1, 0),\n    fed = if_else(\"FED\" %in% tags_vc, 1, 0),\n    hom = if_else(\"H\" %in% tags_vc, 1, 0),\n    ji = if_else(\"JI\" %in% tags_vc, 1, 0),\n    m = if_else(\"M\" %in% tags_vc, 1, 0),\n    nc = if_else(\"NC\" %in% tags_vc, 1, 0),\n    p = if_else(\"P\" %in% tags_vc, 1, 0),\n    ph = if_else(\"PH\" %in% tags_vc, 1, 0),\n    sbs = if_else(\"SBS\" %in% tags_vc, 1, 0),\n    sa = if_else(\"SA\" %in% tags_vc, 1, 0)\n  ) |>\n  ungroup() |>\n  mutate(\n    dna = if_else(is.na(dna), 0, 1),\n    fc = if_else(is.na(fc), 0, 1),\n    mwid = if_else(is.na(mwid), 0, 1),\n    f_mfe = if_else(is.na(f_mfe), 0, 1),\n    p_fa = if_else(is.na(p_fa), 0, 1),\n    om = if_else(is.na(om), 0, 1),\n    ild = if_else(is.na(ild), 0, 1),\n    # calculate the number of years between conviction and exoneration\n    diff_conv_ex = exonerated - convicted,\n    # column that designates whether or not they had the highest severity punishment\n    sentence_severity = if_else(sentence %in% most_severe, \"Yes\", \"No\")\n  ) |>\n  select(-om_tags, -tags_vc, -list_addl_crimes_recode, -tags, -x)\nus_exonerations\n\n# A tibble: 3,284 × 36\n   last_name first_name     age race     sex    state county worst_crime_display\n   <chr>     <chr>        <dbl> <chr>    <chr>  <chr> <chr>  <chr>              \n 1 Abbitt    Joseph          31 Black    Male   Nort… Forsy… Child Sex Abuse    \n 2 Abbott    Cinque          19 Black    Male   Illi… Cook   Drug Possession or…\n 3 Abdal     Warith Habib    43 Black    Male   New … Erie   Sexual Assault     \n 4 Abernathy Christopher     17 White    Male   Illi… Cook   Murder             \n 5 Abney     Quentin         32 Black    Male   New … New Y… Robbery            \n 6 Abrego    Eruby           20 Hispanic Male   Illi… Cook   Murder             \n 7 Acero     Longino         35 Hispanic Male   Cali… Santa… Sex Offender Regis…\n 8 Adams     Anthony         26 Hispanic Male   Cali… Los A… Manslaughter       \n 9 Adams     Cheryl          26 White    Female Mass… Essex  Theft              \n10 Adams     Darryl          25 Black    Male   Texas Dallas Sexual Assault     \n# ℹ 3,274 more rows\n# ℹ 28 more variables: sentence <chr>, convicted <dbl>, exonerated <dbl>,\n#   dna <dbl>, fc <dbl>, mwid <dbl>, f_mfe <dbl>, p_fa <dbl>, om <dbl>,\n#   ild <dbl>, posting_date <chr>, ars <dbl>, cdc <dbl>, ciu <dbl>, csh <dbl>,\n#   cv <dbl>, fem <dbl>, fed <dbl>, hom <dbl>, ji <dbl>, m <dbl>, nc <dbl>,\n#   p <dbl>, ph <dbl>, sbs <dbl>, sa <dbl>, diff_conv_ex <dbl>,\n#   sentence_severity <chr>\n\nskimr::skim(us_exonerations)\n\n\nData summary\n\n\nName\nus_exonerations\n\n\nNumber of rows\n3284\n\n\nNumber of columns\n36\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n10\n\n\nnumeric\n26\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nlast_name\n0\n1.00\n2\n18\n0\n2034\n0\n\n\nfirst_name\n0\n1.00\n2\n18\n0\n1305\n0\n\n\nrace\n0\n1.00\n5\n22\n0\n9\n0\n\n\nsex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nstate\n0\n1.00\n4\n20\n0\n84\n0\n\n\ncounty\n60\n0.98\n3\n17\n0\n568\n0\n\n\nworst_crime_display\n0\n1.00\n5\n29\n0\n45\n0\n\n\nsentence\n0\n1.00\n2\n45\n0\n480\n0\n\n\nposting_date\n0\n1.00\n8\n10\n0\n1230\n0\n\n\nsentence_severity\n0\n1.00\n2\n3\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nage\n26\n0.99\n28.43\n10.24\n11\n20\n26\n34\n83\n▇▆▂▁▁\n\n\nconvicted\n0\n1.00\n1998.64\n10.97\n1956\n1990\n1998\n2007\n2021\n▁▁▇▇▅\n\n\nexonerated\n0\n1.00\n2010.45\n8.96\n1989\n2003\n2013\n2018\n2023\n▂▃▅▇▇\n\n\ndna\n0\n1.00\n0.17\n0.38\n0\n0\n0\n0\n1\n▇▁▁▁▂\n\n\nfc\n0\n1.00\n0.12\n0.33\n0\n0\n0\n0\n1\n▇▁▁▁▁\n\n\nmwid\n0\n1.00\n0.27\n0.44\n0\n0\n0\n1\n1\n▇▁▁▁▃\n\n\nf_mfe\n0\n1.00\n0.24\n0.42\n0\n0\n0\n0\n1\n▇▁▁▁▂\n\n\np_fa\n0\n1.00\n0.63\n0.48\n0\n0\n1\n1\n1\n▅▁▁▁▇\n\n\nom\n0\n1.00\n0.59\n0.49\n0\n0\n1\n1\n1\n▆▁▁▁▇\n\n\nild\n0\n1.00\n0.27\n0.44\n0\n0\n0\n1\n1\n▇▁▁▁▃\n\n\nars\n0\n1.00\n0.03\n0.16\n0\n0\n0\n0\n1\n▇▁▁▁▁\n\n\ncdc\n0\n1.00\n0.13\n0.34\n0\n0\n0\n0\n1\n▇▁▁▁▁\n\n\nciu\n0\n1.00\n0.20\n0.40\n0\n0\n0\n0\n1\n▇▁▁▁▂\n\n\ncsh\n0\n1.00\n0.02\n0.13\n0\n0\n0\n0\n1\n▇▁▁▁▁\n\n\ncv\n0\n1.00\n0.20\n0.40\n0\n0\n0\n0\n1\n▇▁▁▁▂\n\n\nfem\n0\n1.00\n0.09\n0.28\n0\n0\n0\n0\n1\n▇▁▁▁▁\n\n\nfed\n0\n1.00\n0.04\n0.20\n0\n0\n0\n0\n1\n▇▁▁▁▁\n\n\nhom\n0\n1.00\n0.39\n0.49\n0\n0\n0\n1\n1\n▇▁▁▁▅\n\n\nji\n0\n1.00\n0.07\n0.25\n0\n0\n0\n0\n1\n▇▁▁▁▁\n\n\nm\n0\n1.00\n0.03\n0.18\n0\n0\n0\n0\n1\n▇▁▁▁▁\n\n\nnc\n0\n1.00\n0.40\n0.49\n0\n0\n0\n1\n1\n▇▁▁▁▆\n\n\np\n0\n1.00\n0.24\n0.43\n0\n0\n0\n0\n1\n▇▁▁▁▂\n\n\nph\n0\n1.00\n0.01\n0.09\n0\n0\n0\n0\n1\n▇▁▁▁▁\n\n\nsbs\n0\n1.00\n0.01\n0.10\n0\n0\n0\n0\n1\n▇▁▁▁▁\n\n\nsa\n0\n1.00\n0.27\n0.44\n0\n0\n0\n1\n1\n▇▁▁▁▃\n\n\ndiff_conv_ex\n0\n1.00\n11.80\n9.84\n0\n4\n9\n18\n58\n▇▅▂▁▁\n\n\n\n\n\n\n\nData description\nHave an initial draft of your data description section. Your data description should be about your analysis-ready data.\nThe US exonerations data is from the National Registry of Exonerations. This is funded by University of Michigan, Michigan State University, and University of California Irvine. There are 26 columns and 3.2K rows. This data set contains all of the exonerations in the US since 1989. The rows are each individual who was exonerated of their crime, meaning that they were wrongfully found guilty but in the end found innocent on all crimes. The columns are the information about the individual, such as how long they were in jail, their race, name, age, state, and crime. The registry gets their data from the courts and government agencies, so it contains all of the known exonerations. The National Registry of Exonerations’ goal is to change the criminal justice system by highlighting the amount of exonerations there are and making individuals more aware.\n\n\nData limitations\nBecause this dataset is constantly being updated, there are some inconsistencies with the data and the provided codebook. For example, there are tags that exist in our data but not in the codebook. Further, there are some issue with inconsistencies in how data has been entered into the database, particularly in the lack of a standardized format for the sentencing. There is also a question of how accurate the data is, given that they are reporting on exoneration cases more than 30 years ago.\nAnother limitation about this data set is the amount of observations. Although there are several thousand in total, when we start to try to analyze subgroups we may run into the issue of having too few observations.\n\n\nExploratory data analysis\nPerform an (initial) exploratory data analysis.\nFirst, to get a general sense of the dataset, we look at some basic summary statistics for variables of interest.\n\n# proportion of males to females\nus_exonerations |>\n  group_by(sex) |>\n  summarize(\n    num = n()\n  ) |>\n  ungroup() |>\n  mutate(\n    prop = num / sum(num)\n  )\n\n# A tibble: 2 × 3\n  sex      num   prop\n  <chr>  <int>  <dbl>\n1 Female   284 0.0865\n2 Male    3000 0.914 \n\n# proportion of exonerees by race\nus_exonerations |>\n  group_by(race) |>\n  summarize(\n    num = n()\n  ) |>\n  ungroup() |>\n  mutate(\n    prop = num / sum(num)\n  )\n\n# A tibble: 9 × 3\n  race                     num     prop\n  <chr>                  <int>    <dbl>\n1 Asian                     32 0.00974 \n2 Black                   1724 0.525   \n3 Black;#White               1 0.000305\n4 Don't Know                 7 0.00213 \n5 Hispanic                 400 0.122   \n6 Native American           22 0.00670 \n7 Native American;#White     1 0.000305\n8 Other                     19 0.00579 \n9 White                   1078 0.328   \n\n# in how many cases was DNA evidence a significant portion of the exoneration case?\nus_exonerations |>\n  summarize(\n    dna_sum = sum(dna)\n  )\n\n# A tibble: 1 × 1\n  dna_sum\n    <dbl>\n1     574\n\n# on average, how long were exonerees convicted for before their exoneration?\nus_exonerations |>\n  summarize(\n    mean_exon = mean(diff_conv_ex)\n  )\n\n# A tibble: 1 × 1\n  mean_exon\n      <dbl>\n1      11.8\n\n# what is the distribution of exoneration case evidence (DNA, perjury, false confession, etc.)\nus_exonerations |>\n  summarize(\n    dna_sum = sum(dna),\n    fc_sum = sum(fc),\n    mwid_sum = sum(mwid),\n    fmfe_sum = sum(f_mfe),\n    pfa_sum = sum(p_fa),\n    om_sum = sum(om),\n    ild_sum = sum(ild)\n  )\n\n# A tibble: 1 × 7\n  dna_sum fc_sum mwid_sum fmfe_sum pfa_sum om_sum ild_sum\n    <dbl>  <dbl>    <dbl>    <dbl>   <dbl>  <dbl>   <dbl>\n1     574    401      892      773    2079   1938     879\n\n# what proportion of people receive a severe sentence>\nus_exonerations |>\n  group_by(sentence_severity) |>\n  summarize(\n    num = n()\n  ) |> \n  ungroup() |>\n  mutate (\n    prop = num / sum(num)\n  )\n\n# A tibble: 2 × 3\n  sentence_severity   num  prop\n  <chr>             <int> <dbl>\n1 No                 2423 0.738\n2 Yes                 861 0.262\n\n\nNext, we look at some visualizations for some potentially important relationships.\n\n# box plot to show median length between conviction and exoneration by race\n# for visualization purposes, we consider only 5 races, Asian, Hispanic, Black, White, and Native American\nrace_5 <- c('Asian', 'Hispanic', 'Black', 'White', 'Native American')\n\nus_exonerations |>\n  filter(race %in% race_5) |>\n  ggplot(aes(x = race, y = diff_conv_ex, color = race)) +\n  geom_boxplot(show.legend = FALSE) +\n  scale_color_viridis_d() +\n  labs(\n    title = \"Median years between conviction and exoneration by race\",\n    subtitle = \"U.S. Exonerees, 1989 to 2023\",\n    x = \"Exoneree Race\",\n    y = \"Years between conviction and exoneration\",\n    caption = \"Source: The National Registry of Exonerations\"\n  ) +\n  theme_minimal()\n\n\n\n\nThis plot raises some interesting questions regarding race and time between years between conviction and exoneration as we can see some differences in the medians between the races. Is there some relationship between these two factors? If so, how might this interact with the severity of the sentence? We examine part of this idea in the next visualization.\n\nus_exonerations |>\n  filter(race %in% race_5) |>\n  ggplot(aes(x = sentence_severity, fill = race)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_viridis_d() +\n  scale_y_continuous(labels = scales::percent) +\n  labs(\n    title = \"Proportions in exoneree's sentence severity by race\",\n    subtitle = \"U.S. Exonerees, 1989 to 2023\",\n    x = \"Sentence severity: was the sentence death, life, or life without parole?\",\n    y = NULL,\n    fill = \"Race\"\n  ) +\n  theme_minimal()\n\n\n\n\nIn this plot, we aim to show the breakdown of sentence severity by race. Does race on its own play a role in determining how severe the sentence that exonerees get? We will need further analyses to answer this question.\n\ncrime_5 <- c('Sex Offender Registration', 'Tax Evasion/Fraud', 'Weapon Possession or Sale', 'Fraud', 'Child Sex Abuse')\nus_exonerations |>\n  filter(race %in% race_5,\n         worst_crime_display %in% crime_5) |>\n  ggplot(aes(x = diff_conv_ex, y = worst_crime_display, color = race)) +\n  geom_boxplot() +\n  scale_color_viridis_d() +\n  labs(\n    title = \"Years between conviction and exoneration for\\nsevere crimes by race\",\n    subtitle = \"U.S. Exonerees, 1989 to 2023\",\n    x = \"Years between conviction and exoneration\",\n    y = \"Type of Crime\",\n    caption = \"Source: The National Registry of Exonerations\"\n    ) +\n  theme_minimal()\n\n\n\n\nIn this plot, we breakdown the relationship between the type of crime and the years between conviction and exoneration by race. What crimes have the greatest time between conviction and exoneration? How does race compare to the results for each crime?\nCan we draw parallels between the severity of the crime and the severity of the sentence? How does race, or other factors, play a role in changing this relationship? These are questions that we would hope to answer with more analyses.\nAnother facet we can look at is the age at the time of the crime.\n\nus_exonerations |>\n  ggplot(aes(x = age, color = sentence_severity)) +\n  geom_density() +\n  scale_color_viridis_d() +\n  theme_minimal() +\n  labs(\n    title = \"Density plot of age at time of crime by severity of sentence\",\n    subtitle = \"U.S. exonorees 1989-2023, 'severe' sentences are death, life in prison\",\n    x = \"Age at time of supposed crime\",\n    y = \"Density\",\n    color = \"Severe Sentence\"\n  )\n\nWarning: Removed 26 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\nInterestingly, we can see that the distributions look very similar. Both severe sentence exonerees and other exonerees have a peak around 20.\n\n\nQuestions for reviewers\nList specific questions for your peer reviewers and project mentor to answer in giving you feedback on this phase.\nWe would appreciate feedback to our research question: do you think the scope is clear and challenging enough for the purpose of this project?\nWe would also like feedback on our explorations: do they answer our research question and did we make the right choices in which data visualization we used?"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Marvelous Hitmontop",
    "section": "",
    "text": "In this report, we investigate how race affects the severity of sentence and length of time between conviction and exoneration for U.S. exonerees. We use data from the National Registry of Exonerations to develop logistic and linear regression models to explore the differences in outcomes between minority and non-minority exonerees. We find that Hispanic exonerees have a significantly different probability of a severe sentence than White exonerees and generate a confidence interval that suggests the true proportion of Hispanic exonerees that receive a severe sentence is lower than White exonerees. We also find that Black exonerees appear to spend more time between conviction and exoneration than White exonerees. Our findings shed a light on the complex factors that influence exoneree outcomes in the United States and suggests paths for future research."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This project was developed by marvelous-hitmontop For INFO 2950: Introduction to Data Science at Cornell University. The team is comprised of the following team members.\n\nDerrick Chia: Sophomore, Infosci\nCynthia Lei: Sophomore, Infosci\nAlexa Prague: Sophomore, Information Science\nKhushi Patel: Sophomore, Infosci\nCaleb Chin: Sopomore, Infosci"
  },
  {
    "objectID": "pre-registration.html",
    "href": "pre-registration.html",
    "title": "Project title",
    "section": "",
    "text": "In our first analysis, we will explore the relationship between the race of the exonerees and the severity of the sentence that they received. More specifically, we will ask, are minority exonerees more likely to get life in prison/death sentences than non-minority (White) exonerees? To conduct this analysis, we will create a logistic regression model which we will use to generate and visualize predicted probabilities of whether or not the sentence was a life in prison/death sentence based on the race of the exoneree. In addition, we will analyze whether or not race alone can be a good predictor of sentence severity.\nAlthough there are many factors that could contribute to the severity of the sentence of the exoneree (which will be examined in other analyses), we choose to highlight just race with this specific analysis to further explore its impact on the judicial system.\n\n\n\nWe hypothesize that minorities (Black, Hispanic, Asian, and Native American) will be found more likely to receive life in prison/death sentences than White exonerees. However, we also hypothesize that race alone will be a generally poor predictor of the race of the exoneree."
  },
  {
    "objectID": "report.html",
    "href": "report.html",
    "title": "Project title",
    "section": "",
    "text": "Introduction\n\n\nData description\n\n\nData analysis\n\n\nEvaluation of significance\n\n\nInterpretation and conclusions\n\n\nLimitations\n\n\nAcknowledgments"
  },
  {
    "objectID": "appendicies.html",
    "href": "appendicies.html",
    "title": "Project title",
    "section": "",
    "text": "library(tidyverse)\nlibrary(janitor)\nlibrary(tidymodels)\nlibrary(parsnip)\nlibrary(infer)\nlibrary(tidytext)\n\n\nData cleaning\nFirst, we request and download the raw .csv file from the National Registry of Exonerations webpage.\nNext, we load the csv file into a data frame. We name it us_exonerations.\n\n# load data into tibble\nus_exonerations <- read_csv(\"data/us_exonerations.csv\")\n\nRows: 3284 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (20): Last Name, First Name, Race, Sex, State, County, Tags, Worst Crime...\ndbl  (3): Age, Convicted, Exonerated\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe dataset is already generally clean and tidy, with each row representing a exoneree and the various details of their case. However, there are some improvements to be made. First is the column names, which do not follow convention and include several strange characters in them. We use the janitor function clean_names to give the names a proper format.\nWe filter the dataframe by the five most commonly appearing race categories: Asian, Hispanic, Black, White, and Native American. The other race categories were either not well-defined (e.g. Other, unknown, etc.) or contained only 1 observation.\nWe also create a new column named diff_conv_ex that represents the number of years between when an exoneree was convicted and when they were exonerated. This gives us an estimate of how long they spent in prison, on probation, or, more generally, faced the consequences of a crime they did not commit. We also add a column sentence_severity, which marks whether or not the exoneree was sentenced to a severe punishment (death, life in prison, or life without parole). This variable serves as a binary outcome variable for our logistic regression. We create a similar field sentence_severity_3, which further stratifies the exoneree’s sentence into 3 categories (Life in prison/death, some years in prison, probation/no sentence). This variable will serve as a predictor variable in our linear regression model.\nWe relevel the race column so that White exonerees are the baseline dummy variable in our models. This allows us to more easily answer questions relating to difference between White exonerees and non-White exonerees.\nWe also only select the columns that we use in the analysis in one way or another in the final report.\n\nmost_severe <- c(\"Death\", \"Life without parole\", \"Life\")\n\nrace_5 <- c('Asian', 'Hispanic', 'Black', 'White', 'Native American')\n\nb1 <- c(\"Murder\",\n\"Manslaughter\",\n\"Attempted Murder\",\n\"Accessory to Murder\",\n\"Sexual Assault\")\n\nb2 <- c(\"Child Sex Abuse\",\n\"Child Abuse\",\n\"Robbery\",\n\"Assault\",\n\"Arson\")\n\nb3 <- c(\"Kidnapping\",\n\"Terrorism\",\n\"Supporting Terrorism\",\n\"Attempt, Violent\",\n\"Other Violent Felony\")\n\nb4 <- c(\"Burglary/Unlawful Entry\",\n\"Theft\",\n\"Forgery\",\n\"Possession of Stolen Property\",\n\"Destruction of Property\")\n\nb5 <- c(\"Drug Possession or Sale\",\n\"Gun Possession or Sale\",\n\"Other Weapon Possession or Sale\",\n\"Sex Offender Registration\",\n\"Tax Evasion/Fraud\")\n\nb6 <- c(\"Immigration\",\n\"Fraud\",\n\"Bribery\",\n\"Perjury\",\n\"Official Misconduct\")\n\nb7 <- c(\"Traffic Offense\",\n\"Conspiracy\",\n\"Solicitation\",\n\"Obstruction of Justice\",\n\"Failure to Pay Child Support\")\n\nb8 <- c(\"Dependent Adult Abuse\",\n\"Attempt, Nonviolent\",\n\"Other Nonviolent Felony\",\n\"Military Justice Offense\",\n\"Menacing\")\n\nb9 <- c(\"Stalking\",\n\"Harassment\",\n\"Threats\",\n\"Filing a False Report\",\n\"Other\")\n\n# turn tags into columns, mark 1 if tag present, 0 if not\nus_exonerations <- us_exonerations |>\n  clean_names() |>\n  mutate(\n    # calculate the number of years between conviction and exoneration\n    diff_conv_ex = exonerated - convicted,\n    # column that designates whether or not they had the highest severity punishment\n    sentence_severity = if_else(sentence %in% most_severe, \"Yes\", \"No\"),\n    sentence_severity = factor(sentence_severity, levels = c(\"Yes\", \"No\"))\n  ) |>\n  mutate(\n    # bucket worst crime displayed by severity\n     wc_bucket = case_when(\n      worst_crime_display %in% b1 ~ \"b1\",\n      worst_crime_display %in% b2 ~ \"b2\",\n      worst_crime_display %in% b3 ~ \"b3\",\n      worst_crime_display %in% b4 ~ \"b4\",\n      worst_crime_display %in% b5 ~ \"b5\",\n      worst_crime_display %in% b6 ~ \"b6\",\n      worst_crime_display %in% b7 ~ \"b7\",\n      worst_crime_display %in% b8 ~ \"b8\",\n      worst_crime_display %in% b9 ~ \"b9\",\n      .default = NA\n    ),\n    # additional severity stratification when using severity as predictor var\n    sentence_severity_3 = case_when(\n      sentence %in% most_severe ~ \"Life in prison/death\",\n      str_detect(sentence, \"[0-9]+\") ~ \"Some prison sentence\",\n      .default = \"Probation/not sentenced/unknown\"\n    ),\n      race = fct_relevel(race, levels = c(\"White\", \"Black\", \"Hispanic\", \"Native American\", \"Asian\"))\n  ) |>\n  select(race, sentence, sentence_severity, sentence_severity_3, worst_crime_display, sex, wc_bucket, diff_conv_ex) |>\n  filter(race %in% race_5)\n\n\nus_exonerations |>\n  write_csv(\"data/tidy_us_exonerations.csv\")\n\nWe write the tidy dataframe to tidy_us_exonerations.csv in the data folder.\n\n\nOther appendicies (as necessary)"
  },
  {
    "objectID": "proposal.html",
    "href": "proposal.html",
    "title": "Race and U.S. Exonerations",
    "section": "",
    "text": "library(tidyverse)\nlibrary(skimr)"
  },
  {
    "objectID": "proposal.html#introduction-and-data",
    "href": "proposal.html#introduction-and-data",
    "title": "Race and U.S. Exonerations",
    "section": "Introduction and data",
    "text": "Introduction and data\n\nIdentify the source of the data.\n\nSource: NYC Open Data\n\nState when and how it was originally collected (by the original data curator, not necessarily how you found the data).\n\nThis dataset is updated everyday and it is collected by the Department of Health and Mental Hygiene.\n\nWrite a brief description of the observations.\n\nEach row represents a date of interest which is separated into three types: date of diagnosis, date of hospital admission, and date of death. This dataset represents citywide and borough-specific daily counts of COVID-19 confirmed cases and COVID-related hospitalizations and confirmed and probable deaths among New York City residents. Columns include number of cases on date of interest, hospitalized count, death count in different boroughs, etc."
  },
  {
    "objectID": "proposal.html#research-question",
    "href": "proposal.html#research-question",
    "title": "Race and U.S. Exonerations",
    "section": "Research question",
    "text": "Research question\n\nA well formulated research question. (You may include more than one research question if you want to receive feedback on different ideas for your project. However, one per data set is required.)\n\nWhat is the trend between the date of interest and the number of cases, deaths, and hospitalizations on that date citywide?\nWhat is the trend between the date of interest and the number of deaths for each borough?\n\nA description of the research topic along with a concise statement of your hypotheses on this topic.\n\nThe data collected will show the number of cases, deaths, and hospitalizations on a specific date citywide. I believe that there will be quite a few fluctuations as we know that COVID-19 had specific periods of major outbreaks.\n\nIdentify the types of variables in your research question. Categorical? Quantitative?\n\nDate: Categorical\nDeaths: quantitative\nHospitalizations: quantitative\nCases: Quantitative\nBorough: categorical"
  },
  {
    "objectID": "proposal.html#glimpse-of-data",
    "href": "proposal.html#glimpse-of-data",
    "title": "Race and U.S. Exonerations",
    "section": "Glimpse of data",
    "text": "Glimpse of data\n\nCOVID <- read_csv(\"data/COVID-19_Daily_Counts_of_Cases__Hospitalizations__and_Deaths.csv\")\n\nRows: 1106 Columns: 67\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): date_of_interest\ndbl (66): CASE_COUNT, PROBABLE_CASE_COUNT, HOSPITALIZED_COUNT, DEATH_COUNT, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nskimr::skim(COVID)\n\n\nData summary\n\n\nName\nCOVID\n\n\nNumber of rows\n1106\n\n\nNumber of columns\n67\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nnumeric\n66\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ndate_of_interest\n0\n1\n10\n10\n0\n1106\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nCASE_COUNT\n0\n1\n2456.34\n4984.53\n0\n601.00\n1473.5\n2793.75\n55008\n▇▁▁▁▁\n\n\nPROBABLE_CASE_COUNT\n0\n1\n481.01\n625.08\n0\n96.00\n357.5\n652.00\n5882\n▇▁▁▁▁\n\n\nHOSPITALIZED_COUNT\n0\n1\n170.76\n243.71\n0\n47.00\n100.5\n181.00\n1840\n▇▁▁▁▁\n\n\nDEATH_COUNT\n0\n1\n34.89\n75.76\n0\n6.00\n13.0\n30.00\n598\n▇▁▁▁▁\n\n\nPROBABLE_DEATH_COUNT\n0\n1\n5.80\n24.30\n0\n0.00\n1.0\n2.00\n240\n▇▁▁▁▁\n\n\nCASE_COUNT_7DAY_AVG\n0\n1\n2455.27\n4577.64\n0\n613.50\n1549.5\n2836.50\n39498\n▇▁▁▁▁\n\n\nALL_CASE_COUNT_7DAY_AVG\n0\n1\n2935.97\n5121.63\n0\n765.25\n1932.5\n3547.75\n43954\n▇▁▁▁▁\n\n\nHOSP_COUNT_7DAY_AVG\n0\n1\n170.68\n239.41\n0\n48.00\n104.0\n180.00\n1662\n▇▁▁▁▁\n\n\nDEATH_COUNT_7DAY_AVG\n0\n1\n34.88\n74.87\n0\n7.00\n12.0\n29.00\n566\n▇▁▁▁▁\n\n\nALL_DEATH_COUNT_7DAY_AVG\n0\n1\n40.67\n97.87\n0\n8.00\n13.0\n31.75\n775\n▇▁▁▁▁\n\n\nBX_CASE_COUNT\n0\n1\n405.56\n930.34\n0\n80.00\n201.5\n427.00\n10560\n▇▁▁▁▁\n\n\nBX_PROBABLE_CASE_COUNT\n0\n1\n94.84\n143.35\n0\n14.00\n63.0\n127.75\n1575\n▇▁▁▁▁\n\n\nBX_HOSPITALIZED_COUNT\n0\n1\n36.77\n56.35\n0\n9.00\n20.0\n39.00\n390\n▇▁▁▁▁\n\n\nBX_DEATH_COUNT\n0\n1\n6.58\n15.87\n0\n1.00\n2.0\n5.00\n132\n▇▁▁▁▁\n\n\nBX_PROBABLE_DEATH_COUNT\n0\n1\n1.12\n5.02\n0\n0.00\n0.0\n0.00\n46\n▇▁▁▁▁\n\n\nBX_CASE_COUNT_7DAY_AVG\n0\n1\n405.39\n835.87\n0\n82.00\n229.5\n450.50\n7480\n▇▁▁▁▁\n\n\nBX_PROBABLE_CASE_COUNT_7DAY_AVG\n0\n1\n94.79\n131.76\n0\n15.25\n70.0\n132.75\n1094\n▇▁▁▁▁\n\n\nBX_ALL_CASE_COUNT_7DAY_AVG\n0\n1\n500.19\n959.35\n0\n107.00\n302.0\n584.25\n8574\n▇▁▁▁▁\n\n\nBX_HOSPITALIZED_COUNT_7DAY_AVG\n0\n1\n36.75\n54.94\n0\n9.00\n21.0\n37.00\n358\n▇▁▁▁▁\n\n\nBX_DEATH_COUNT_7DAY_AVG\n0\n1\n6.59\n15.55\n0\n1.00\n2.0\n5.00\n117\n▇▁▁▁▁\n\n\nBX_ALL_DEATH_COUNT_7DAY_AVG\n0\n1\n7.71\n20.28\n0\n1.00\n2.0\n5.00\n158\n▇▁▁▁▁\n\n\nBK_CASE_COUNT\n0\n1\n740.56\n1470.84\n0\n203.25\n454.0\n833.00\n16667\n▇▁▁▁▁\n\n\nBK_PROBABLE_CASE_COUNT\n0\n1\n131.44\n174.73\n0\n29.00\n99.0\n170.50\n1906\n▇▁▁▁▁\n\n\nBK_HOSPITALIZED_COUNT\n0\n1\n51.70\n71.67\n0\n16.00\n30.0\n53.00\n555\n▇▁▁▁▁\n\n\nBK_DEATH_COUNT\n0\n1\n10.88\n23.38\n0\n2.00\n4.0\n9.75\n201\n▇▁▁▁▁\n\n\nBK_PROBABLE_DEATH_COUNT\n0\n1\n1.95\n8.42\n0\n0.00\n0.0\n1.00\n92\n▇▁▁▁▁\n\n\nBK_CASE_COUNT_7DAY_AVG\n0\n1\n740.24\n1357.21\n0\n213.75\n465.5\n842.00\n11587\n▇▁▁▁▁\n\n\nBK_PROBABLE_CASE_COUNT_7DAY_AVG\n0\n1\n131.36\n162.22\n0\n29.00\n104.0\n172.00\n1213\n▇▁▁▁▁\n\n\nBK_ALL_CASE_COUNT_7DAY_AVG\n0\n1\n871.59\n1508.30\n0\n251.00\n570.5\n1027.50\n12787\n▇▁▁▁▁\n\n\nBK_HOSPITALIZED_COUNT_7DAY_AVG\n0\n1\n51.68\n70.06\n0\n17.00\n31.0\n52.00\n490\n▇▁▁▁▁\n\n\nBK_DEATH_COUNT_7DAY_AVG\n0\n1\n10.89\n22.94\n0\n2.00\n4.0\n9.00\n178\n▇▁▁▁▁\n\n\nBK_ALL_DEATH_COUNT_7DAY_AVG\n0\n1\n12.84\n30.75\n0\n3.00\n4.0\n10.00\n252\n▇▁▁▁▁\n\n\nMN_CASE_COUNT\n0\n1\n450.75\n903.73\n0\n104.00\n275.5\n485.75\n9114\n▇▁▁▁▁\n\n\nMN_PROBABLE_CASE_COUNT\n0\n1\n88.84\n113.01\n0\n20.00\n67.0\n121.75\n972\n▇▁▁▁▁\n\n\nMN_HOSPITALIZED_COUNT\n0\n1\n25.89\n35.63\n0\n7.00\n16.0\n29.75\n273\n▇▁▁▁▁\n\n\nMN_DEATH_COUNT\n0\n1\n4.78\n9.88\n0\n1.00\n2.0\n5.00\n92\n▇▁▁▁▁\n\n\nMN_PROBABLE_DEATH_COUNT\n0\n1\n0.80\n3.19\n0\n0.00\n0.0\n0.00\n33\n▇▁▁▁▁\n\n\nMN_CASE_COUNT_7DAY_AVG\n0\n1\n450.54\n824.06\n0\n119.00\n291.5\n470.75\n6394\n▇▁▁▁▁\n\n\nMN_PROBABLE_CASE_COUNT_7DAY_AVG\n0\n1\n88.77\n106.61\n0\n19.50\n73.0\n126.50\n766\n▇▁▁▁▁\n\n\nMN_ALL_CASE_COUNT_7DAY_AVG\n0\n1\n539.30\n924.27\n0\n147.25\n365.0\n595.00\n7161\n▇▁▁▁▁\n\n\nMN_HOSPITALIZED_COUNT_7DAY_AVG\n0\n1\n25.88\n34.65\n0\n7.00\n17.0\n30.00\n228\n▇▁▁▁▁\n\n\nMN_DEATH_COUNT_7DAY_AVG\n0\n1\n4.77\n9.58\n0\n1.00\n2.0\n4.00\n73\n▇▁▁▁▁\n\n\nMN_ALL_DEATH_COUNT_7DAY_AVG\n0\n1\n5.56\n12.49\n0\n1.00\n2.0\n4.00\n100\n▇▁▁▁▁\n\n\nQN_CASE_COUNT\n0\n1\n685.39\n1404.20\n0\n145.00\n388.0\n783.00\n15225\n▇▁▁▁▁\n\n\nQN_PROBABLE_CASE_COUNT\n0\n1\n133.17\n168.74\n0\n24.00\n96.0\n190.00\n1609\n▇▁▁▁▁\n\n\nQN_HOSPITALIZED_COUNT\n0\n1\n47.93\n75.40\n0\n13.00\n26.0\n51.00\n609\n▇▁▁▁▁\n\n\nQN_DEATH_COUNT\n0\n1\n10.45\n23.94\n0\n1.00\n4.0\n9.00\n202\n▇▁▁▁▁\n\n\nQN_PROBABLE_DEATH_COUNT\n0\n1\n1.67\n7.20\n0\n0.00\n0.0\n1.00\n68\n▇▁▁▁▁\n\n\nQN_CASE_COUNT_7DAY_AVG\n0\n1\n685.11\n1298.45\n0\n149.00\n408.5\n814.75\n11551\n▇▁▁▁▁\n\n\nQN_PROBABLE_CASE_COUNT_7DAY_AVG\n0\n1\n133.08\n158.31\n0\n23.00\n101.0\n191.00\n1219\n▇▁▁▁▁\n\n\nQN_ALL_CASE_COUNT_7DAY_AVG\n0\n1\n818.19\n1442.99\n0\n185.00\n527.5\n1036.00\n12689\n▇▁▁▁▁\n\n\nQN_HOSPITALIZED_COUNT_7DAY_AVG\n0\n1\n47.91\n73.99\n0\n12.25\n28.0\n49.00\n562\n▇▁▁▁▁\n\n\nQN_DEATH_COUNT_7DAY_AVG\n0\n1\n10.44\n23.55\n0\n2.00\n4.0\n9.00\n177\n▇▁▁▁▁\n\n\nQN_ALL_DEATH_COUNT_7DAY_AVG\n0\n1\n12.11\n30.31\n0\n2.00\n4.0\n9.00\n240\n▇▁▁▁▁\n\n\nSI_CASE_COUNT\n0\n1\n173.25\n326.49\n0\n40.25\n108.0\n192.75\n3720\n▇▁▁▁▁\n\n\nSI_PROBABLE_CASE_COUNT\n0\n1\n32.66\n35.86\n0\n6.00\n25.5\n48.00\n316\n▇▁▁▁▁\n\n\nSI_HOSPITALIZED_COUNT\n0\n1\n10.52\n11.59\n0\n3.00\n7.0\n14.00\n83\n▇▂▁▁▁\n\n\nSI_DEATH_COUNT\n0\n1\n2.20\n3.80\n0\n0.00\n1.0\n3.00\n34\n▇▁▁▁▁\n\n\nSI_PROBABLE_DEATH_COUNT\n0\n1\n0.25\n0.96\n0\n0.00\n0.0\n0.00\n9\n▇▁▁▁▁\n\n\nSI_PROBABLE_CASE_COUNT_7DAY_AVG\n0\n1\n32.63\n33.33\n0\n6.00\n27.0\n48.00\n233\n▇▂▁▁▁\n\n\nSI_CASE_COUNT_7DAY_AVG\n0\n1\n173.18\n299.80\n0\n40.25\n111.5\n193.00\n2687\n▇▁▁▁▁\n\n\nSI_ALL_CASE_COUNT_7DAY_AVG\n0\n1\n205.79\n328.04\n0\n51.25\n145.0\n243.00\n2907\n▇▁▁▁▁\n\n\nSI_HOSPITALIZED_COUNT_7DAY_AVG\n0\n1\n10.51\n11.06\n0\n4.00\n8.0\n13.00\n72\n▇▂▁▁▁\n\n\nSI_DEATH_COUNT_7DAY_AVG\n0\n1\n2.18\n3.52\n0\n1.00\n1.0\n2.00\n26\n▇▁▁▁▁\n\n\nSI_ALL_DEATH_COUNT_7DAY_AVG\n0\n1\n2.44\n4.32\n0\n1.00\n1.0\n2.00\n34\n▇▁▁▁▁\n\n\nINCOMPLETE\n0\n1\n385.95\n4838.12\n0\n0.00\n0.0\n0.00\n60980\n▇▁▁▁▁"
  },
  {
    "objectID": "proposal.html#introduction-and-data-1",
    "href": "proposal.html#introduction-and-data-1",
    "title": "Race and U.S. Exonerations",
    "section": "Introduction and data",
    "text": "Introduction and data\n\nIdentify the source of the data.\n\nThe source of the data is the Department of Health and Mental Hygiene (DOHMH).\n\nState when and how it was originally collected (by the original data curator, not necessarily how you found the data).\n\nThe original data curators collected raw data through measurements in air quality and composition. It is then adjusted for weather and season and modeled based on the environmental factors and nearby emission sources.\n\nWrite a brief description of the observations.\n\nThe observations describe every NYC neighborhoods’ metrics like outside air pollutants, health burdens, and air toxics."
  },
  {
    "objectID": "proposal.html#research-question-1",
    "href": "proposal.html#research-question-1",
    "title": "Race and U.S. Exonerations",
    "section": "Research question",
    "text": "Research question\n\nA well formulated research question. (You may include more than one research question if you want to receive feedback on different ideas for your project. However, one per data set is required.)\n\nWhat neighborhoods of NYC have highest average levels of fine particulates?, does this show a correlation with the overall air quality?\nHave the Ozone levels in my neighborhood gone down or up over the last few years?\n\nA description of the research topic along with a concise statement of your hypotheses on this topic.\n\nThis data shows air quality over time in NYC neighborhoods. We want to investigate how ozone and air quality has changed over time and if the particular things in the air have an affect on the overall air quality. We believe that a higher level of fine particulates mean a worse air quality and that ozone levels in general, have done down in the last few years.\n\nIdentify the types of variables in your research question. Categorical? Quantitative?\n\nThe variables that want to be known in the research questions are categorical.\n\nName\nPlace\nTime Period\n\nNumerical\n\nDate"
  },
  {
    "objectID": "proposal.html#glimpse-of-data-1",
    "href": "proposal.html#glimpse-of-data-1",
    "title": "Race and U.S. Exonerations",
    "section": "Glimpse of data",
    "text": "Glimpse of data\n\n# add code here\nAir_Qual <- read.csv(\"data/Air_Quality.csv\")\nskimr::skim(Air_Qual)\n\n\nData summary\n\n\nName\nAir_Qual\n\n\nNumber of rows\n16122\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n7\n\n\nlogical\n1\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nName\n0\n1\n10\n76\n0\n19\n0\n\n\nMeasure\n0\n1\n4\n47\n0\n8\n0\n\n\nMeasure.Info\n0\n1\n3\n21\n0\n8\n0\n\n\nGeo.Type.Name\n0\n1\n2\n8\n0\n5\n0\n\n\nGeo.Place.Name\n0\n1\n5\n46\n0\n114\n0\n\n\nTime.Period\n0\n1\n4\n19\n0\n45\n0\n\n\nStart_Date\n0\n1\n10\n10\n0\n36\n0\n\n\n\nVariable type: logical\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\ncount\n\n\n\n\nMessage\n16122\n0\nNaN\n:\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nUnique.ID\n0\n1\n339480.96\n194099.81\n130355\n172183.25\n221882.5\n547749.75\n671122.0\n▇▂▁▂▃\n\n\nIndicator.ID\n0\n1\n427.13\n109.66\n365\n365.00\n375.0\n386.00\n661.0\n▇▁▁▁▂\n\n\nGeo.Join.ID\n0\n1\n613339.41\n7916715.24\n1\n202.00\n303.0\n404.00\n105106107.0\n▇▁▁▁▁\n\n\nData.Value\n0\n1\n19.13\n21.67\n0\n8.46\n13.9\n25.47\n424.7\n▇▁▁▁▁"
  },
  {
    "objectID": "proposal.html#introduction-and-data-2",
    "href": "proposal.html#introduction-and-data-2",
    "title": "Race and U.S. Exonerations",
    "section": "Introduction and data",
    "text": "Introduction and data\n\nIdentify the source of the data.\n\nSource: The National Registry of Exonerations\n\nState when and how it was originally collected (by the original data curator, not necessarily how you found the data).\n\nThe Registry was founded in 2012 as a project of the Newkirk Center for Science and Society at the University of California Irvine, the University of Michigan Law School, and Michigan State University College of Law in conjunction with the Center on Wrongful Convictions at Northwestern University School of Law. Their research allowed them to collect data on every known exoneration in the United States since 1989. \n\nWrite a brief description of the observations.\n\nEach observation represents one exonerated individual. The dataset includes their name, age, race, sex, and various details about the crime they were exonerated for, such as location, type of crime, years of conviction, whether or not DNA was used and more."
  },
  {
    "objectID": "proposal.html#research-question-2",
    "href": "proposal.html#research-question-2",
    "title": "Race and U.S. Exonerations",
    "section": "Research question",
    "text": "Research question\n\nA well formulated research question. (You may include more than one research question if you want to receive feedback on different ideas for your project. However, one per data set is required.)\n\nHow does DNA being collected impact how long they were in jail for?\nAre there any differences in conviction and exoneration rates between races within different states?\nHow does the individual’s characteristics impact how long they were wrongfully convicted for?\n\n\nA description of the research topic along with a concise statement of your hypotheses on this topic.\n\nThe research topic is about every known exoneration in United States since 1989. It gives information about the sentence and the individual who was exonerated. We want to investigate how the individual’s sentence impacts how long the individual was in jail for. We believe that the worse the sentence and the less DNA evidence on the scene, the longer the individual was wrongfully convicted and in jail for.\n\nIdentify the types of variables in your research question. Categorical? Quantitative?\n\nCategorical\n\nRace\nSex\nState\nDescription\nCountry\nDNA being found\n\nQuantitative\n\nYear Convicted\nYear Exonerated\nAge"
  },
  {
    "objectID": "proposal.html#glimpse-of-data-2",
    "href": "proposal.html#glimpse-of-data-2",
    "title": "Race and U.S. Exonerations",
    "section": "Glimpse of data",
    "text": "Glimpse of data\n\n# add code here\nus_exonerations <- \n  read_csv(\"data/us_exonerations.csv\")\n\nRows: 3284 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (20): Last Name, First Name, Race, Sex, State, County, Tags, Worst Crime...\ndbl  (3): Age, Convicted, Exonerated\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nskimr::skim(us_exonerations)\n\n\nData summary\n\n\nName\nus_exonerations\n\n\nNumber of rows\n3284\n\n\nNumber of columns\n23\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n20\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nLast Name\n0\n1.00\n2\n18\n0\n2034\n0\n\n\nFirst Name\n0\n1.00\n2\n18\n0\n1305\n0\n\n\nRace\n0\n1.00\n5\n22\n0\n9\n0\n\n\nSex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nState\n0\n1.00\n4\n20\n0\n84\n0\n\n\nCounty\n60\n0.98\n3\n17\n0\n568\n0\n\n\nTags\n167\n0.95\n1\n28\n0\n443\n0\n\n\nWorst Crime Display\n0\n1.00\n5\n29\n0\n45\n0\n\n\nList Add’l Crimes Recode\n2002\n0.39\n4\n132\n0\n248\n0\n\n\nSentence\n0\n1.00\n2\n45\n0\n480\n0\n\n\nDNA\n2710\n0.17\n3\n3\n0\n1\n0\n\n\n*\n3113\n0.05\n1\n1\n0\n1\n0\n\n\nFC\n2883\n0.12\n2\n2\n0\n1\n0\n\n\nMWID\n2392\n0.27\n4\n4\n0\n1\n0\n\n\nF/MFE\n2511\n0.24\n5\n5\n0\n1\n0\n\n\nP/FA\n1205\n0.63\n4\n4\n0\n1\n0\n\n\nOM\n1346\n0.59\n2\n2\n0\n1\n0\n\n\nILD\n2405\n0.27\n3\n3\n0\n1\n0\n\n\nPosting Date\n0\n1.00\n8\n10\n0\n1230\n0\n\n\nOM Tags\n1347\n0.59\n2\n35\n0\n134\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nAge\n26\n0.99\n28.43\n10.24\n11\n20\n26\n34\n83\n▇▆▂▁▁\n\n\nConvicted\n0\n1.00\n1998.64\n10.97\n1956\n1990\n1998\n2007\n2021\n▁▁▇▇▅\n\n\nExonerated\n0\n1.00\n2010.45\n8.96\n1989\n2003\n2013\n2018\n2023\n▂▃▅▇▇"
  },
  {
    "objectID": "presentation.html",
    "href": "presentation.html",
    "title": "Exonerations in the U.S.",
    "section": "",
    "text": "Installing package into '/home/dc787/R/x86_64-pc-linux-gnu-library/4.2'\n(as 'lib' is unspecified)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.2     ✔ purrr   1.0.0\n✔ tibble  3.2.1     ✔ dplyr   1.1.2\n✔ tidyr   1.2.1     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n\n✔ broom        1.0.2     ✔ rsample      1.1.1\n✔ dials        1.1.0     ✔ tune         1.1.1\n✔ infer        1.0.4     ✔ workflows    1.1.2\n✔ modeldata    1.0.1     ✔ workflowsets 1.0.0\n✔ parsnip      1.0.3     ✔ yardstick    1.1.0\n✔ recipes      1.0.6     \n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\n\n\n\nRows: 3284 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (20): Last Name, First Name, Race, Sex, State, County, Tags, Worst Crime...\ndbl  (3): Age, Convicted, Exonerated\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nThe criminal justice system in the United States has been under scrutiny for its disproportionate impact on minority communities.\nWe want to investigate:\n\nhow race affects the severity of the sentences exonerees receive\nhow length of time between conviction and exoneration, severity of crime, and sentence are related\nhow false convictions are associated with harsher sentences and later found innocent"
  },
  {
    "objectID": "pre-registration.html#questions-and-explanation",
    "href": "pre-registration.html#questions-and-explanation",
    "title": "Project title",
    "section": "Questions and explanation:",
    "text": "Questions and explanation:\nIn our second analysis, we ask: how is the length of time between conviction and exoneration and the worst crime they were convicted of related to how many years the exoneree was sentenced to? To conduct this analysis, we will create a model to examine the relationship between these variables. First, we use a logistic regression model with a binary severity of sentence (whether or not the sentence was life in prison, death) as the dependent variable. Next, with the help of further data tidying, we will transform the sentence variable into a numerical one and create a linear regression model to show the relationship between the length of time between conviction and exoneration and the worst crime they were convicted of and the number of years they were sentenced to.\nThis question is driven by an interest in analyzing the failings of the judicial system. Do false convictions for worse crimes still correlate to harsher sentences? In addition, are people with harsher sentences often left convicted for longer before being exonerated?"
  },
  {
    "objectID": "pre-registration.html#hypothesis-1",
    "href": "pre-registration.html#hypothesis-1",
    "title": "Project title",
    "section": "Hypothesis:",
    "text": "Hypothesis:\nWe hypothesize that longer periods of time between convictions and exoneration will be associated with harsher sentences. We further hypothesize that exonerees that were convicted of worse crimes will also have harsher sentences."
  },
  {
    "objectID": "report.html#modeling-race-and-sentence-severity",
    "href": "report.html#modeling-race-and-sentence-severity",
    "title": "Project title",
    "section": "Modeling race and sentence severity",
    "text": "Modeling race and sentence severity\n\n\n# A tibble: 10 × 3\n# Groups:   race [5]\n   race            sentence_severity     n\n   <fct>           <fct>             <int>\n 1 White           Yes                 283\n 2 White           No                  795\n 3 Black           Yes                 492\n 4 Black           No                 1232\n 5 Hispanic        Yes                  71\n 6 Hispanic        No                  329\n 7 Asian           Yes                   6\n 8 Asian           No                   26\n 9 Native American Yes                   6\n10 Native American No                   16\n\n\nWrite explanation for visualization\n\n\n\n\n\n\n\n# A tibble: 5 × 5\n  term                estimate std.error statistic  p.value\n  <chr>                  <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)           1.03      0.0692    14.9   2.37e-50\n2 raceBlack            -0.115     0.0874    -1.32  1.88e- 1\n3 raceHispanic          0.500     0.148      3.38  7.23e- 4\n4 raceAsian             0.433     0.458      0.946 3.44e- 1\n5 raceNative American  -0.0521    0.484     -0.108 9.14e- 1\n\n\n\n\n\nUsing the coefficient estimates generate by the logistic regression, we are left with the following model:\n\\[\n\\begin{split}\n\\log\\Big(\\frac{p}{1-p}\\Big) = 1.0329 \\\\\n-~0.1150 \\times race~Black \\\\\n+~0.5005 \\times race~Hispanic \\\\\n+~0.4334 \\times race~Asian \\\\\n-~0.0521 \\times race~Native~American\n\\end{split}\n\\]\nWe provide a brief analysis of the elements of this model here and will include a more substantial overview in the interpretation section below.\nBased on the model, we would expect the log odds of not receiving a severe sentence to be lower for Black and Native American exonerees and higher for Hispanic and Asian exonerees when compared to White exonerees. However, before we can conclude anything, we must evaluate if these any of these results are significant."
  },
  {
    "objectID": "report.html#motivation",
    "href": "report.html#motivation",
    "title": "Race and U.S. Exonerations",
    "section": "Motivation",
    "text": "Motivation\nThe data set used for our analysis is from the National Registry of Exonerations, a project founded in 2012 by the Newkirk Center for Science at University of California Irvine, the University of Michigan Law School, and Michigan State University College of Law. The Registry was created in an effort to reduce and prevent future false convictions through the collection and dissemination of accurate and objective information about exonerations in the United States. The data was requested and collected through their website."
  },
  {
    "objectID": "report.html#composition",
    "href": "report.html#composition",
    "title": "Race and U.S. Exonerations",
    "section": "Composition",
    "text": "Composition\nEach observation in the data set represents an individual who was convicted of a crime in the United States and later was found innocent or had their charges acquitted after a re-examination of their case. There are 3284 observations in the data set as of the date it was collected from the Registry (early April 2023), but we use 3256 observations after filtering for the five most frequently occuring race categories. The Registry has collected data from every known exoneration in the United States between 1989 and 2023. The Registry is a living data collection project that is constantly adding and discovering new information about exonerations. Thus, we can consider this data set as a sample (albeit a very comprehensive one) of all U.S. exonerees.\nIndividual observations include a myriad of information regarding the exoneree and the circumstances of their case. Among the 23 fields in the original data set, there are personal information fields detailing the name, race, and sex of the exoneree, as well as fields that detail information about the exoneration itself, such as the length of time the exoneree spent in prison, the crime of which they were convicted, their sentence, and the conditions that eventually led to their exoneration.\nThere are some errors/imperfections in this data set, mainly due to inconsistent data entry combined with an outdated codebook. This combination means that some values and/or fields are largely not intelligible. To the best of our capabilities, we exclude these observations and fields from our analyses.\nWhile this data only consists of publicly available information regarding U.S. exonerees, it does reveal personal and potentially sensitive information about each exoneree, such as their name, sex, and race. Further, it is possible that some of the content in this data set might be anxiety-inducing due to the nature of the crimes that the exonerees were accused of committing.\n\n\n\nThe data set identifies several subpopulations, including by race. There are 9 race categories in the data set, with 5 of them being used in our analysis: Asian (n = 1078), Black (n = 1724), White (n = 32), Hispanic (n = 400), Native American (n = 22). The other race categories are either not well defined (“Other” or “Don’t Know”) or contain only one observation so are omitted."
  },
  {
    "objectID": "report.html#preprocessingcleaninglabeling",
    "href": "report.html#preprocessingcleaninglabeling",
    "title": "Race and U.S. Exonerations",
    "section": "Preprocessing/cleaning/labeling",
    "text": "Preprocessing/cleaning/labeling\nWe clean all field names using the janitor package. We create 4 new fields, one that indicates the number of years between conviction and exoneration (diff_conv_ex), and two that represent various stratification of the sentence field for use in our analysis (sentence_severity and sentence_severity_3). The fourth field (wc_bucket) represents ‘buckets’ of the worst crime for which exonerees were falsely convicted. There are 9 buckets, with 5 crimes in each bucket. This is discussed in more detail later in the report. Finally, we filter out fields that we do not make use of in our analyses. For more information on the cleaning and preprocessing of the data, see the Appendix section on data cleaning.\nThe “raw” data can be found in the us_exonerations.csv file in our GitHub repo."
  },
  {
    "objectID": "report.html#uses",
    "href": "report.html#uses",
    "title": "U.S. Exonerations",
    "section": "Uses",
    "text": "Uses\nThis dataset has been used in many other reports across a variety of topics, many of which can be accessed through the National Registry of Exonerations website."
  },
  {
    "objectID": "report.html#analysis-1",
    "href": "report.html#analysis-1",
    "title": "U.S. Exonerations",
    "section": "Analysis 1:",
    "text": "Analysis 1:\nWe find that, while race may seem like a significant factor within the criminal justice system, it does not seem to have a strong relationship with sentence severity when isolated as a predictive variable. Only 1 out of the 5 races showed a significant difference of the probability of receiving a severe sentence when compared to a baseline category (in this case, White exonerees). ### Predictive power?\n\ninsert further interpretation of analysis one here."
  },
  {
    "objectID": "report.html#analysis-2-1",
    "href": "report.html#analysis-2-1",
    "title": "U.S. Exonerations",
    "section": "Analysis 2:",
    "text": "Analysis 2:\nNote, refine after sig. test for analysis 2 is done. Early analysis suggests that, holding years between conviction and exoneration constant, being in the higher crime buckets greatly increases the predicted probability of having a severe sentence. This confirms the general trends of the justice system as we hypothesized in our preregistration."
  },
  {
    "objectID": "presentation.html#race-and-sentence-severity",
    "href": "presentation.html#race-and-sentence-severity",
    "title": "Exonerations in the U.S.",
    "section": "Race and Sentence Severity",
    "text": "Race and Sentence Severity\nThis plot raises some interesting questions regarding race and time between years between conviction and exoneration as we can see some differences in the medians between the races. Is there some relationship between these two factors? If so, how might this interact with the severity of the sentence? We examine part of this idea in the next visualization.\n\nIn this plot, we aim to show the breakdown of sentence severity by race. Does race on its own play a role in determining how severe the sentence that exonerees get? We will need further analyses to answer this question."
  },
  {
    "objectID": "presentation.html#modeling-sentence-severity-vs.-race",
    "href": "presentation.html#modeling-sentence-severity-vs.-race",
    "title": "Exonerations in the U.S.",
    "section": "Modeling sentence severity vs. race",
    "text": "Modeling sentence severity vs. race\n\n\nSignificance: were the differences in predicted probability of receiving a severe sentence just due to random chance?"
  },
  {
    "objectID": "presentation.html#predicting-sentence-severity-with-race",
    "href": "presentation.html#predicting-sentence-severity-with-race",
    "title": "Exonerations in the U.S.",
    "section": "Predicting sentence severity with race",
    "text": "Predicting sentence severity with race\n\n\nSignificance of results at 5% significance level: Hispanic Exonerees vs White Exonerees"
  },
  {
    "objectID": "presentation.html#predicting-time-falsely-convicted-using-race-and-sentence-severity",
    "href": "presentation.html#predicting-time-falsely-convicted-using-race-and-sentence-severity",
    "title": "Exonerations in the U.S.",
    "section": "Predicting time falsely convicted using race and sentence severity",
    "text": "Predicting time falsely convicted using race and sentence severity\n\n\nSignificance of results at 5% significance level: Black Exonerees vs White Exonerees, Sentence Severity"
  },
  {
    "objectID": "presentation.html#more-highlights-from-eda",
    "href": "presentation.html#more-highlights-from-eda",
    "title": "Exonerations in the U.S.",
    "section": "More Highlights from EDA",
    "text": "More Highlights from EDA\n\n\n\n\n\n\n  \n    \n    \n      mean_exon\n    \n  \n  \n    11.80359\n  \n  \n  \n\n\n\n\n\n\n\n\n  \n    \n    \n      dna_sum\n      fc_sum\n      mwid_sum\n      fmfe_sum\n      pfa_sum\n      om_sum\n      ild_sum\n    \n  \n  \n    574\n401\n892\n773\n2079\n1938\n879\n  \n  \n  \n\n\n\n\n\n\n\n\n  \n    \n    \n      sentence_severity\n      num\n      prop\n    \n  \n  \n    Yes\n861\n0.2621803\n    No\n2423\n0.7378197"
  },
  {
    "objectID": "presentation.html#visualizations-for-potential-important-relationships",
    "href": "presentation.html#visualizations-for-potential-important-relationships",
    "title": "Exonerations in the U.S.",
    "section": "Visualizations for potential important relationships",
    "text": "Visualizations for potential important relationships\nNext, we look at some visualizations for some potentially important relationships."
  },
  {
    "objectID": "report.html#evaluation-of-significance-analysis-3",
    "href": "report.html#evaluation-of-significance-analysis-3",
    "title": "U.S. Exonerations",
    "section": "Evaluation of significance: Analysis 3",
    "text": "Evaluation of significance: Analysis 3\n\n\n# A tibble: 7 × 2\n  term                                             p_value\n  <chr>                                              <dbl>\n1 intercept                                          0    \n2 raceAsian                                          0.24 \n3 raceBlack                                          0    \n4 raceHispanic                                       0.466\n5 raceNative American                                0.18 \n6 sentence_severityProbation/not sentenced/unknown   0    \n7 sentence_severitySome prison sentence              0"
  },
  {
    "objectID": "presentation.html#predicting-time-between-conviction-and-exoneration-using-race-and-sentence-severity",
    "href": "presentation.html#predicting-time-between-conviction-and-exoneration-using-race-and-sentence-severity",
    "title": "Exonerations in the U.S.",
    "section": "Predicting time between conviction and exoneration using race and sentence severity",
    "text": "Predicting time between conviction and exoneration using race and sentence severity\n\n\nSignificance of results at 5% significance level: Black Exonerees vs White Exonerees, Sentence Severity"
  },
  {
    "objectID": "presentation.html#time-falsely-convicted-race-and-sentence-severity",
    "href": "presentation.html#time-falsely-convicted-race-and-sentence-severity",
    "title": "Exonerations in the U.S.",
    "section": "Time falsely convicted, race, and sentence severity",
    "text": "Time falsely convicted, race, and sentence severity\n\n\nSignificance of results at 5% significance level: Black Exonerees vs White Exonerees, Sentence Severity"
  },
  {
    "objectID": "presentation.html#topic-and-motivation",
    "href": "presentation.html#topic-and-motivation",
    "title": "Exonerations in the U.S.",
    "section": "Topic and motivation",
    "text": "Topic and motivation\n\n\n\n\n\n\n\nThe criminal justice system in the United States has been under scrutiny for its disproportionate impact on minority communities.\nWe want to investigate:\n\nhow race affects the severity of the sentences exonerees receive\nhow length of time between conviction and exoneration, severity of crime, and sentence are related"
  },
  {
    "objectID": "presentation.html#data-introduction",
    "href": "presentation.html#data-introduction",
    "title": "Exonerations in the U.S.",
    "section": "Data introduction",
    "text": "Data introduction\n\nObservations represent all known U.S. exonerees between 1989 and 2023.\nData was collected by The National Registry of Exonerations\nThe data fields consist of exoneree information such as name, race, and sex as well as information about their exoneration.\nData has several subpopulations"
  },
  {
    "objectID": "report.html#predicting-sentence-severity-with-race",
    "href": "report.html#predicting-sentence-severity-with-race",
    "title": "Race and U.S. Exonerations",
    "section": "Predicting sentence severity with race",
    "text": "Predicting sentence severity with race\n\n\n\nFirst, we analyze whether we would expect sentence severity to change with race using a logistic regression model. We use a binary sentence severity variable, with “Severe” indicating a life in prison or death sentence, and “Not Severe” indicating any other sentence. We include observations from the five most commonly occurring races in the data set: Asian, Hispanic, Black, White, and Native American. Since we want to compare how severe sentencing differs between minority and White exonerees, we use White as the baseline variable. This yields the model:\n\\[\n\\begin{split}\n\\log\\Big(\\frac{p}{1-p}\\Big) = 1.0329 \\\\\n-~0.1150 \\times race~Black\n+~0.5005 \\times race~Hispanic \\\\\n+~0.4334 \\times race~Asian\n-~0.0521 \\times race~Native~American\n\\end{split}\n\\]\nWe can use this model to generate predictions about the probability of receiving a severe sentence.\n\n\n\n\n\nThe predicted probability of a severe sentence for Black and Native American exonerees is higher than White exonerees, whereas the probabilities for Hispanic and Asian exonerees are lower than White exonerees. Before we can interpret these results, we must first determine if any of these results are statistically significant.\n\nEvaluation of significance:\nWe conduct a hypothesis test to measure whether the regression coefficients determined above are significantly different than 0 (suggesting some relationship between the race and sentence severity) or if the observed differences are due to random chance. We use variables \\(R_B, R_H, R_A, R_N\\) (for raceBlack, raceHispanic, raceAsian, and raceNativeAmerican respectively) to represent the coefficients of the stratified race variable shown in the model. In our hypothesis, we use the general \\(R_i\\) to represent all coefficients in the model for brevity.\nFor our analysis, we use a significance level of \\(\\alpha = 0.05\\).\nNull Hypothesis: \\[ H_0: R_i  = 0\\] Our null hypothesis states that the log odds (and therefore also the predicted probability) of not receiving a severe sentence is not different for exonerees of the race designated by \\(i\\) and White exonerees (the baseline variable).\nAlternative Hypothesis: \\[ H_A: R_i \\ne 0\\] Our alternative hypothesis states that the log odds (and therefore also the predicted probability) of not receiving a severe sentence is different for exonerees of the race designated by \\(i\\) and White exonerees (the baseline variable).\n\n\n\n\n\n\n  \n    \n    \n      \n      term\n      p_value\n    \n  \n  \n    1\nintercept\n0.886\n    2\nraceAsian\n0.346\n    3\nraceBlack\n0.166\n    4\nraceHispanic\n0.000\n    5\nraceNative American\n0.896\n  \n  \n  \n\n\n\n\nFor all race categories except Hispanic, the p-value leads us to the following conclusion:\nSince the p-value is greater than the significance level (\\(\\alpha = 0.05\\)), we fail to reject the null hypothesis in favor of the alternative hypothesis. The data does not provide convincing evidence that Asian, Black, or Native American exonerees have a different log odds of receiving a severe sentence than White exonerees. This implies that the data does not provide convincing evidence that the true probability of receiving a severe sentence is different between Asian, Black, Native American, and White exonerees.\nFor the Hispanic race category, the p-value leads us to the following conclusion:\nSince the p-value is less than the significance level (\\(\\alpha = 0.05\\)), we reject the null hypothesis in favor of the alternative hypothesis. The data provides convincing evidence that Hispanic exonerees have a different log odds of receiving a severe sentence than White exonerees. This implies that there is a difference in true probability of receiving a severe sentence between Hispanic and White exonerees.\nThe lack of significance among most of the race groups suggests that race alone does not give us much information about whether or not an exoneree receives a severe sentence.\nOne facet that this model fails to consider is the severity of the crimes that the exonerees were falsely convicted of. What if the proportions of exonerees being falsely convicted of more severe crimes are different across races? This could skew the results of our analysis.\nTo explore the answer to this question, we look to another field in our data set: worst_crime_display."
  },
  {
    "objectID": "report.html#evaluation-of-significance",
    "href": "report.html#evaluation-of-significance",
    "title": "U.S. Exonerations",
    "section": "Evaluation of significance:",
    "text": "Evaluation of significance:\nWe conduct a hypothesis test to measure whether the regression coefficients determined above are significantly different than 0 (suggesting some relationship between the race and sentence severity) or if the observed differences are due to random chance. We use variables \\(R_B, R_H, R_A, R_N\\) (for raceBlack, raceHispanic, raceAsian, and raceNativeAmerican respectively) to represent the coefficients of the stratified race variable shown in the model. In our hypothesis, we use the general \\(R_i\\) to represent all coefficients in the model for brevity.\nFor our analysis, we use a significance level of \\(\\alpha = 0.05\\).\nNull Hypothesis: \\[ H_0: \\R_i  = 0\\] Our null hypothesis states that the log odds (and therefore also the predicted probability) of not receiving a severe sentence is not different for exonerees of the race designated by \\(i\\) and White exonerees (the baseline variable).\nAlternative Hypothesis: \\[ H_A: R_i \\ne 0\\] Our alternative hypothesis states that the log odds (and therefore also the predicted probability) of not receiving a severe sentence is different for exonerees of the race designated by \\(i\\) and White exonerees (the baseline variable).\nHypothesis testing of the logistic regression coefficients\n\n\n# A tibble: 5 × 2\n  term                p_value\n  <chr>                 <dbl>\n1 intercept             0.886\n2 raceAsian             0.346\n3 raceBlack             0.166\n4 raceHispanic          0    \n5 raceNative American   0.896\n\n\nFor all race categories except Hispanic, the p-value leads us to the following conclusion:\nSince the p-value is greater than the significance value (\\(\\alpha = 0.05\\)), we fail to reject the null hypothesis in favor of the alternative hypothesis. The data does not provide convincing evidence that Asian, Black, or Native American exonerees have a different log odds of receiving a severe sentence than White exonerees. This implies that the data does not provide convincing evidence that the true probability of receiving a severe sentence is different between Asian, Black, Native American, and White exonerees.\nFor the Hispanic race category, the p-value leads us to the following conclusion:\nSince the p-value is less than the signifiance value (\\(\\alpha = 0.05\\)), we reject the null hypothesis in favor of the alternative hypothesis. The data provides convincing evidence that Hispanic exonerees have a different log odds of receiving a severe sentence than White exonerees. This implies that there is a difference in true probability of receiving a severe sentence between Hispanic and White exonerees.\nThe lack of significance among most of the race groups suggests that race alone does not give us much information about whether or not the exoneree received a severe sentence.\nOne facet that this model fails to consider is the severity of the crimes that the exonerees were falsely convicted of. What if the proportions of exonerees being falsely convicted of more severe crimes are different across races? This could have skew the results of our analysis.\nTo explore the answer to this question, we look to another field in our data set: worst_crime_display."
  },
  {
    "objectID": "report.html#analysis-2",
    "href": "report.html#analysis-2",
    "title": "U.S. Exonerations",
    "section": "Analysis 2:",
    "text": "Analysis 2:\nEarly analysis suggests that, holding years between conviction and exoneration constant, being in the higher crime buckets greatly increases the predicted probability of having a severe sentence. This confirms the general trends of the justice system as we hypothesized in our preregistration. In other words, we failed to reject the null hypothesis. We found that more generally, the trend that Hispanic exonerees had less severe sentences than White exoneeres. This does not mean that there is no racial bias in the justice system. This is simply one data set, and one kind of analysis. We cannot generalize to the entire population. In addition, other factors and variables could have been the reason why we got these results."
  },
  {
    "objectID": "report.html#evaluation-of-significance-analysis-2",
    "href": "report.html#evaluation-of-significance-analysis-2",
    "title": "U.S. Exonerations",
    "section": "Evaluation of significance: Analysis 2",
    "text": "Evaluation of significance: Analysis 2\nAs with the first model we built, we conduct a hypothesis test on the coefficients of our model. For brevity, we omit the full model in this report, but it can be found in the appendix. We represent the coefficients in our model with variables \\(R_i\\) and \\(WC_j\\), where \\(R_i\\) represents the coefficient for the race represented by \\(i\\) as before, and \\(WC_j\\) represents the coefficient for the crime bucket represented by \\(j\\) (\\(j\\) is one of b1, b2, …).\nNull Hypotheses: \\[ H_0: R_i = 0, ~WC_j ~constant~~\\forall j \\in (b1...b9)\\] Our null hypothesis for \\(R_i\\) states that the log odds (and therefore also the predicted probability) of not receiving a severe sentence is not different for exonerees of the race designated by \\(i\\) and White exonerees (the baseline variable), holding crime severity bucket constant.\nAlternative Hypothesis: \\[H_A: R_i \\ne 0, ~WC_j ~constant~~\\forall j \\in (b1...b9)\\] Our alternative hypothesis for \\(R_i\\) states that the log odds (and therefore also the predicted probability) of not receiving a severe sentence is different for exonerees of the race designated by \\(i\\) and White exonerees (the baseline variable), holding crime severity bucket constant.\n\n\n# A tibble: 13 × 2\n   term                p_value\n   <chr>                 <dbl>\n 1 intercept             0    \n 2 raceAsian             0.852\n 3 raceBlack             0.214\n 4 raceHispanic          0    \n 5 raceNative American   0.794\n 6 wc_bucketb2           0    \n 7 wc_bucketb3           0    \n 8 wc_bucketb4           0    \n 9 wc_bucketb5           0    \n10 wc_bucketb6           0    \n11 wc_bucketb7           0    \n12 wc_bucketb8           0    \n13 wc_bucketb9           0    \n\n\nUsing a significance level of \\(\\alpha = 0.05\\), the p-value for \\(R_H\\) leads us to the following conclusion:\nSince the p-value of \\(R_H\\) is less than the significance level of \\(\\alpha = 0.05\\), we reject the null hypothesis in favor of the alternative hypothesis. The data provide convincing evidence that Hispanic exonerees have a different log odds (and thus predicted probability) of receiving a severe sentence than White exonerees, holding crime severity bucket constant.\nUsing a significance level of \\(\\alpha = 0.05\\), the p-value for all other \\(R_i\\) leads us to the following conclusion:\nSince the p-value for all \\(R_i\\) is greater than the significance level of \\(\\alpha = 0.05\\), we fail to reject the null hypothesis in favor of the alternative hypothesis. The data does not provide conclusive evidence that the log odds (and predicted probabilities) of receiving a severe sentence are different between White exonerees and the race category specified by \\(i\\), holding crime severity bucket constant.\nThese results suggest that, even accounting for crime severity, the predicted probability of an exoneree receiving a severe sentence does not seem to be different among race categories with White exonerees as a baseline except for Hispanic exonerees.\nBecause both of our models and hypothesis tests suggests that Hispanic exonerees are associated with a difference in predicted probability when compared to White exonerees, we conduct a confidence interval to generate an estimate of the magnitude and direction of this difference.\n\n\n# A tibble: 1 × 2\n  lower_ci upper_ci\n     <dbl>    <dbl>\n1   -0.125  -0.0321\n\n\nUsing bootstrapping, we generate the following 95% confidence interval for the difference in proportion of Hispanic exonerees and White exonerees who received a severe sentence:\n\\[\np_H - p_W \\in (-0.126, -0.024)\n\\] Thus, we are 95% confident that the true proportion of Hispanic exonerees who received a severe sentence is between -0.126 and -0.024 lower than the true proportion of White exonerees who received a severe sentence.\nTo deepen our analysis of the impacts of race in the cases of U.S. exonerees, we shift our focus from the sentencing for a false conviction to the consequences of a false conviction for exonerees. Namely, we are curious to see if race has an impact on the number of years between conviction and exoneration."
  },
  {
    "objectID": "report.html#evaluation-of-significance-modelling-years-falsely-convicted",
    "href": "report.html#evaluation-of-significance-modelling-years-falsely-convicted",
    "title": "U.S. Exonerations",
    "section": "Evaluation of significance: modelling years falsely convicted",
    "text": "Evaluation of significance: modelling years falsely convicted\nAs before, we use \\(R_i\\) to designate the coefficient in our model associated with the race \\(i\\) (e.g. \\(R_B\\) designates variable raceBlack). We use \\(SV_k\\) to indicate the level of sentence severity where \\(k\\) represents one of the three outcomes (\\(SV_L\\) represents life in prison or death, \\(SV_P\\) represents some prison sentence, and \\(SV_NP\\) represents probation or no sentence).\nNull Hypotheses: \\[ H_0: R_i = 0, ~SV_k ~constant~~\\forall k \\in (L, P, NP) \\] Our null hypothesis for \\(R_i\\) states that the number of years falsely convicted is not different between the race denoted by \\(i\\) and White exonerees (the baseline variable), holding sentence severity bucket constant.\nAlternative Hypothesis: \\[ H_0: R_i \\ne 0, ~SV_k ~constant~~\\forall k \\in (L, P, NP) \\] Our alternative hypothesis for \\(R_i\\) states that the number of years falsely convicted is not different between the race denoted by \\(i\\) and White exonerees (the baseline variable), holding sentence severity bucket constant.\n\n\n# A tibble: 7 × 2\n  term                                             p_value\n  <chr>                                              <dbl>\n1 intercept                                          0    \n2 raceAsian                                          0.24 \n3 raceBlack                                          0    \n4 raceHispanic                                       0.466\n5 raceNative American                                0.18 \n6 sentence_severityProbation/not sentenced/unknown   0    \n7 sentence_severitySome prison sentence              0    \n\n\nSince the p-value for \\(R_B\\) is less than the significance level of \\(\\alpha = 0.05\\), we reject the null hypothesis in favor of the alternative hypothesis. The data provide convincing evidence that the true number of years falsely convicted is, on average, different than between Black and White exonerees, holding sentence severity constant.\nTo estimate the magnitude of this difference in mean number of years falsely convicted between White and Black exonerees, we create a confidence interval.\n\n\n# A tibble: 1 × 2\n  lower_ci upper_ci\n     <dbl>    <dbl>\n1     3.04     4.45\n\n\nUsing bootstrapping, we generate the following 95% confidence interval for the difference in mean years falsely convicted between Black exonerees and White exonerees:\n\\[\\mu_B - \\mu_W \\in~(3.035, 4.435)\\] This means that we are 95% confident that at the population level, Black exonerees, on average, are falsely convicted between 3.035 and 4.435 years longer than White exonerees."
  },
  {
    "objectID": "report.html#analysis-3-using-sentence-severity-as-a-predictor",
    "href": "report.html#analysis-3-using-sentence-severity-as-a-predictor",
    "title": "Race and U.S. Exonerations",
    "section": "Analysis 3: Using sentence severity as a predictor",
    "text": "Analysis 3: Using sentence severity as a predictor\nNext, we combine the elements of each of the previous analyses to model exoneree outcomes after the sentencing. More specifically, we are curious to see if race has an impact on the number of years between conviction and exoneration.\nWe aim to model how long an exoneree will spend between conviction and exoneration using race, their sentence severity, and severity of their crime. To do this, we construct a linear regression model with diff_conv_ex (number of years between conviction and exoneration) as the outcome variable and race, sentence_severity_3and `wc_bucket as predictor variables. In this analysis, we provide more granularity to the sentence-severity variable by splitting outcomes into 3 cases: life in prison/death, some other prison sentence, probation/no sentence. This additional stratification will allow us to examine the differences in the time between conviction and exoneration more deeply than with a binary sentence outcome.\n\n\n# A tibble: 15 × 2\n  term                estimate\n  <chr>                  <dbl>\n1 (Intercept)           15.5  \n2 raceBlack              3.76 \n3 raceHispanic           0.659\n4 raceNative American    2.62 \n5 raceAsian             -1.37 \n# ℹ 10 more rows\n\n\n\n\n\nUpon visual inspection, we can see several differences in predicted number of years falsely convicted in all three severity levels, particularly when comparing Native American and Black exonerees to White exonerees. We conduct a hypothesis test to see if any of these differences are significant.\n\nEvaluation of significance\nAs before, we use \\(R_i\\) to designate the coefficient in our model associated with the race \\(i\\) (e.g. \\(R_B\\) designates variable raceBlack) and \\(WC_j\\) to designate the worst crime displayed bucket. We use \\(SV_k\\) to indicate the level of sentence severity where \\(k\\) represents one of the three outcomes (\\(SV_L\\) represents life in prison or death, \\(SV_P\\) represents some prison sentence, and \\(SV_{NP}\\) represents probation or no sentence).\nNull Hypotheses: \\[ H_0: R_i = 0, ~SV_k ~constant~~\\forall k \\in (L, P, NP), ~WC_j ~constant~~\\forall j \\in (b1...b9)  \\] Our null hypothesis for \\(R_i\\) states that the number of years falsely convicted is not different between the race denoted by \\(i\\) and White exonerees (the baseline variable), holding sentence severity bucket and worst crime displayed bucket constant.\nAlternative Hypothesis: \\[ H_0: R_i \\ne 0, ~SV_k ~constant~~\\forall k \\in (L, P, NP), ~WC_j ~constant~~\\forall j \\in (b1...b9) \\] Our alternative hypothesis for \\(R_i\\) states that the number of years falsely convicted is not different between the race denoted by \\(i\\) and White exonerees (the baseline variable), holding sentence severity bucket and worst crime displayed bucket constant.\n\n\n# A tibble: 15 × 2\n  term                p_value\n  <chr>                 <dbl>\n1 intercept             0    \n2 raceAsian             0.454\n3 raceBlack             0    \n4 raceHispanic          0.278\n5 raceNative American   0.208\n# ℹ 10 more rows\n\n\nNote: we omit the remaining rows for brevity, but the p-values for all \\(SV_k\\) and \\(WC_j\\) are p < 0.05.\nSince the p-value for \\(R_B\\) is less than the significance level of \\(\\alpha = 0.05\\), we reject the null hypothesis in favor of the alternative hypothesis. The data provide convincing evidence that the true number of years falsely convicted is, on average, different than between Black and White exonerees, holding sentence severity and worst crime severity constant.\nTo estimate the magnitude of this difference in mean number of years falsely convicted between White and Black exonerees, we create a confidence interval.\n\n\n\nUsing bootstrapping, we generate the following 95% confidence interval for the difference in mean years falsely convicted between Black exonerees and White exonerees:\n\\[\\mu_B - \\mu_W \\in~(3.035, 4.435)\\] This means that we are 95% confident that at the population level, Black exonerees, on average, are falsely convicted between 3.035 and 4.435 years longer than White exonerees. This suggests that Black exonerees tend to remain convicted for longer than White exonerees, potentially providing evidence that Black exonerees could be looked over for exoneration cases."
  },
  {
    "objectID": "report.html#adding-worst-crime-displayed",
    "href": "report.html#adding-worst-crime-displayed",
    "title": "Race and U.S. Exonerations",
    "section": "Adding worst crime displayed",
    "text": "Adding worst crime displayed\nworst_crime_display indicates the worst crime that the exoneree was convicted of. Crimes are designated as “worse” in accordance to the National Registry of Exoneration codebook. For ease of analysis and brevity, we bucket these crimes by severity, with 5 crimes in each bucket and 9 buckets total. Lower bucket numbers represent more severe crimes. For example, b1 (bucket 1) contains murder, manslaughter, attempted murder, accessory to murder, and sexual assault whereas b9 (bucket 9) contains stalking, harassment, threats, filing a false report and other.\n\n\n\nWe add this new bucketed field into our original model to show the effects of worst crime displayed and race on sentence severity. We can use this model to generate and visualize predictions for combinations of worst crime and race. We isolate the first three buckets (b1, b2, b3) as the crime severities that are most likely to lead to a severe sentence.\n\n\n\n\n\n\nEvaluation of significance\nAs with the first model we built, we conduct a hypothesis test on the coefficients of our model. For brevity, we omit the full model in this report. We represent the coefficients in our model with variables \\(R_i\\) and \\(WC_j\\), where \\(R_i\\) represents the coefficient for the race represented by \\(i\\) as before, and \\(WC_j\\) represents the coefficient for the crime bucket represented by \\(j\\) (\\(j\\) is one of b1, b2, …).\nNull Hypotheses: \\[ H_0: R_i = 0, ~WC_j ~constant~~\\forall j \\in (b1...b9)\\] Our null hypothesis for \\(R_i\\) states that the log odds (and therefore also the predicted probability) of not receiving a severe sentence is not different for exonerees of the race designated by \\(i\\) and White exonerees (the baseline variable), holding crime severity bucket constant.\nAlternative Hypothesis: \\[H_A: R_i \\ne 0, ~WC_j ~constant~~\\forall j \\in (b1...b9)\\] Our alternative hypothesis for \\(R_i\\) states that the log odds (and therefore also the predicted probability) of not receiving a severe sentence is different for exonerees of the race designated by \\(i\\) and White exonerees (the baseline variable), holding crime severity bucket constant.\n\n\n\n\n\n\n  \n    \n    \n      \n      term\n      p_value\n    \n  \n  \n    1\nintercept\n0.000\n    2\nraceAsian\n0.852\n    3\nraceBlack\n0.214\n    4\nraceHispanic\n0.000\n    5\nraceNative American\n0.794\n    6..12\n\n\n    13\nwc_bucketb9\n0.000\n  \n  \n  \n\n\n\n\nNote: we omit the rest of the rows for brevity, but the p-value for all wc_bucket coefficients is p < 0.001.\nUsing a significance level of \\(\\alpha = 0.05\\), the p-value for \\(R_H\\) leads us to the following conclusion:\nSince the p-value of \\(R_H\\) is less than the significance level of \\(\\alpha = 0.05\\), we reject the null hypothesis in favor of the alternative hypothesis. The data provide convincing evidence that Hispanic exonerees have a different log odds (and thus predicted probability) of receiving a severe sentence than White exonerees, holding crime severity bucket constant.\nUsing a significance level of \\(\\alpha = 0.05\\), the p-value for all other \\(R_i\\) leads us to the following conclusion:\nSince the p-value for all \\(R_i\\) is greater than the significance level of \\(\\alpha = 0.05\\), we fail to reject the null hypothesis in favor of the alternative hypothesis. The data does not provide conclusive evidence that the log odds (and predicted probabilities) of receiving a severe sentence are different between White exonerees and the race category specified by \\(i\\), holding crime severity bucket constant.\nThese results suggest that, even accounting for crime severity, the predicted probability of an exoneree receiving a severe sentence does not seem to be different among race categories with White exonerees as a baseline except for Hispanic exonerees.\nBecause both of our models and hypothesis tests suggests that Hispanic exonerees are associated with a difference in predicted probability when compared to White exonerees, we conduct a confidence interval to generate an estimate of the magnitude and direction of this difference.\n\n\n\nUsing bootstrapping, we generate the following 95% confidence interval for the difference in proportion of Hispanic exonerees and White exonerees who received a severe sentence:\n\\[\np_H - p_W \\in (-0.126, -0.024)\n\\]\nThus, we are 95% confident that the true proportion of Hispanic exonerees who received a severe sentence is between -0.126 and -0.024 lower than the true proportion of White exonerees who received a severe sentence. What does this imply? The difference between these two groups of exonerees could be indicative of differences in sentencing between White and Hispanic exonerees, or could be a consequence of several limitations in our data and model, which we will discuss later."
  },
  {
    "objectID": "report.html#dataset-limitations",
    "href": "report.html#dataset-limitations",
    "title": "Race and U.S. Exonerations",
    "section": "Dataset limitations",
    "text": "Dataset limitations\nBecause this dataset is constantly being updated, there are some inconsistencies with the data and the provided codebook. For example, there are tags that exist in our data but not in the codebook. Further, there are some issue with inconsistencies in how data has been entered into the database, particularly in the lack of a standardized format for the sentencing, which made it difficult to transform into a numeric estimate. There is also a question of how accurate the data is, given that they are reporting on exoneration cases from more than 30 years ago.\nAnother limitation in this data set is the amount of observations. Although there are several thousand in total, when analyzing subgroups (such as race), some categories have very few observations.\nOne key limitation to this dataset in the context of the real world is that it is contained to people who have already been exonerated. It does not represent all falsely convicted people and thus any interpretations we make cannot be extrapolated to the rest of the prison population. Future analyses could consider combining datasets to analyze both current prisoners and exonerees at the same time."
  },
  {
    "objectID": "report.html#analysis-limitations",
    "href": "report.html#analysis-limitations",
    "title": "Race and U.S. Exonerations",
    "section": "Analysis limitations",
    "text": "Analysis limitations\nOne key limitation to our analyses is our use of bucketing/generalization of several of our variables. sentence_severity is a binary variable that tries to represent hundreds of different sentence outcomes. This loss of specificity prevents us from analyzing many details that could lead to different results. Further, wc_bucket generalizes several crimes into the same severity level based on a single perspective of crime severity given by the codebook. This leaves much room for debate about the accuracy of these buckets and prevents analyses from a crime by crime basis.\nAnother limitation to our analyses are missing explanatory variables that could change the outcomes of interest. In interest of maintaining simplicity, we did not include several variables in our models that could have presented different conclusions, such as age, county that the exoneree was convicted in, and more."
  },
  {
    "objectID": "report.html#analyzing-length-of-time-falsely-convicted",
    "href": "report.html#analyzing-length-of-time-falsely-convicted",
    "title": "Race and U.S. Exonerations",
    "section": "Analyzing length of time falsely convicted",
    "text": "Analyzing length of time falsely convicted\nNext, we combine the elements of each of the previous analyses to model exoneree outcomes after the sentencing. More specifically, we are curious to see if race has an impact on the number of years between conviction and exoneration.\nWe aim to model how long an exoneree will spend between conviction and exoneration using race, their sentence severity, and severity of their crime. To do this, we construct a linear regression model with diff_conv_ex (number of years between conviction and exoneration) as the outcome variable and race, sentence_severity_3and `wc_bucket as predictor variables. In this analysis, we provide more granularity to the sentence-severity variable by splitting outcomes into 3 cases: life in prison/death, some other prison sentence, probation/no sentence. This additional stratification will allow us to examine the differences in the time between conviction and exoneration more deeply than with a binary sentence outcome.\n\n\n\n\n\n\n  \n    \n    \n      \n      term\n      estimate\n    \n  \n  \n    1\n(Intercept)\n15.5181247\n    2\nraceBlack\n3.7622943\n    3\nraceHispanic\n0.6585421\n    4\nraceNative American\n2.6180583\n    5\nraceAsian\n-1.3738708\n    6..14\n\n\n    15\nwc_bucketb9\n-6.0884043\n  \n  \n  \n\n\n\n\n\n\n\nUpon visual inspection, we can see several differences in predicted number of years falsely convicted in all three severity levels, particularly when comparing Native American and Black exonerees to White exonerees. We conduct a hypothesis test to see if any of these differences are significant.\n\nEvaluation of significance\nAs before, we use \\(R_i\\) to designate the coefficient in our model associated with the race \\(i\\) (e.g. \\(R_B\\) designates variable raceBlack) and \\(WC_j\\) to designate the worst crime displayed bucket. We use \\(SV_k\\) to indicate the level of sentence severity where \\(k\\) represents one of the three outcomes (\\(SV_L\\) represents life in prison or death, \\(SV_P\\) represents some prison sentence, and \\(SV_{NP}\\) represents probation or no sentence).\nNull Hypotheses: \\[ H_0: R_i = 0, ~SV_k ~constant~~\\forall k \\in (L, P, NP), ~WC_j ~constant~~\\forall j \\in (b1...b9)  \\] Our null hypothesis for \\(R_i\\) states that the number of years falsely convicted is not different between the race denoted by \\(i\\) and White exonerees (the baseline variable), holding sentence severity bucket and worst crime displayed bucket constant.\nAlternative Hypothesis: \\[ H_0: R_i \\ne 0, ~SV_k ~constant~~\\forall k \\in (L, P, NP), ~WC_j ~constant~~\\forall j \\in (b1...b9) \\] Our alternative hypothesis for \\(R_i\\) states that the number of years falsely convicted is not different between the race denoted by \\(i\\) and White exonerees (the baseline variable), holding sentence severity bucket and worst crime displayed bucket constant.\n\n\n\n\n\n\n  \n    \n    \n      \n      term\n      p_value\n    \n  \n  \n    1\nintercept\n0.000\n    2\nraceAsian\n0.454\n    3\nraceBlack\n0.000\n    4\nraceHispanic\n0.278\n    5\nraceNative American\n0.206\n    6..14\n\n\n    15\nwc_bucketb9\n0.020\n  \n  \n  \n\n\n\n\nNote: we omit the remaining rows for brevity, but the p-values for all \\(SV_k\\) and \\(WC_j\\) are p < 0.05.\nSince the p-value for \\(R_B\\) is less than the significance level of \\(\\alpha = 0.05\\), we reject the null hypothesis in favor of the alternative hypothesis. The data provide convincing evidence that the true number of years falsely convicted is, on average, different than between Black and White exonerees, holding sentence severity and worst crime severity constant.\nTo estimate the magnitude of this difference in mean number of years falsely convicted between White and Black exonerees, we create a confidence interval.\n\n\n\nUsing bootstrapping, we generate the following 95% confidence interval for the difference in mean years falsely convicted between Black exonerees and White exonerees:\n\\[\\mu_B - \\mu_W \\in~(3.035, 4.435)\\] This means that we are 95% confident that at the population level, Black exonerees, on average, are falsely convicted between 3.035 and 4.435 years longer than White exonerees. This suggests that Black exonerees tend to remain convicted for longer than White exonerees, potentially providing evidence that Black exonerees could be looked over for exoneration cases.\nSince the rest of the p-values for \\(R_i\\) is less than the significance level of \\(\\alpha = 0.05\\), we fail to reject the null hypothesis. The data fails to provide convincing evidence that the true number of years falsely convicted is, on average, different for Asian, Native, and Hispanic exonerees when compared to White exonerees, holding sentence severity and worst crime severity constant."
  }
]